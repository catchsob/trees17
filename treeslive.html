<title>Trees TF.js</title>
<div id="select">Image: <input type="file" id="select_img" accept="image/*, capture=camera" onchange="preview()"></div>
<div>Prediction: <label id="pred"></label>/ Confidence: <label id="conf"></label></div>
<input id="livebutton" type="button" value="live" onclick="goLive()">
<div id="live"></div>
<br>
<img id="preview_img" /><br>

<style type="text/css">
    div, input {
        font-size: 4vw;
    }
    label {
        color: brown;
    }
    img {
        width: 100vmin;
        height: auto;
    }
</style>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
<script>
    const MODEL_NAME = 'YOUR_MODEL_TFJS';
    const ENV = 'env.json'
    const LABELS_NAME = 'YOUR_LABELS';
    const IMAGE_SIZE = 448;
    let env;
    let model = null;
    let labels;
    let video;
    let track = null;
    let canvas;
    let liveapp;
    let info = 'loading...';
    let infocolor = 'black';
    let live = false;
    let liveview = null;
    
    function goLive() {
        live = !live;
        if (live) {
            document.getElementById("preview_img").style.visibility = 'hidden';
            initLive();
        }
        else {
            if (liveview != null) {
                liveapp.removeChild(liveview);
                liveview = null;
            }
            if (track != null) {  // release camera
                track.stop();
                track = null;
            }
            if (video.src.active) {
                video.src.stop();
            }
            video = null;
            cnavas = null;
            document.getElementById("preview_img").style.visibility = 'visible';
        }
    }
    
    function preview() {
        if (!window.FileReader) {
            console.log('no preview functionality supported by your browser!');
            return;
        }
        
        let reader = new FileReader();
        reader.onload = function (event) {
            let img = document.getElementById("preview_img");
            img.src = event.target.result;
            img.onload = () => {  // wait for img be loaded, or img will be all zeros
                predict(img);
            }
        };

        let file = document.getElementById("select_img").files[0];
        reader.readAsDataURL(file);
    }
    
    async function init() {
        console.log('start ...');
        env = loadEnv(ENV);
        labels = loadLabels(env[LABELS_NAME]).split("\r\n");
        console.log('labels ' + env[LABELS_NAME] + ' loaded.');
        model = await tf.loadGraphModel(env[MODEL_NAME]);
        console.log('model ' + env[MODEL_NAME] + ' loaded.');
    }
    
    async function predict(imgElement) {
        const logits = tf.tidy(() => {
            const img = tf.cast(tf.browser.fromPixels(imgElement).resizeBilinear([IMAGE_SIZE, IMAGE_SIZE]), 'float32');
            const offset = tf.scalar(255.0);
            const normalized = img.div(offset);
            const batched = normalized.reshape([1, IMAGE_SIZE, IMAGE_SIZE, 3]);
            return model.predict(batched);
        });
        
        const values = await logits.data();
        let p = -1;
        let v = -0.1;
        for (let i = 0; i < values.length; i++) {
            if (values[i] > v) {
                v = values[i];
                p = i;
            }
        }
        document.getElementById("pred").innerHTML = labels[p];
        info = labels[p];
        document.getElementById("conf").innerHTML = v.toPrecision(4);
        if (v > 0.9) {
            infocolor = "green";
        }
        else if (v > 0.7) {
            infocolor = "yellow";
        }
        else if (v > 0.5) {
            infocolor = "red";
        }
        else {
            infocolor = "black";
        }
        console.log({value: v, index: p, label: labels[p]});
        logits.dispose(); // prevent from WebGL memory leak
        //console.log(tf.memory());
    }
    
    function loadFile(filePath) {
        var result = null;
        var xmlhttp = new XMLHttpRequest();
        xmlhttp.open("GET", filePath, false);
        xmlhttp.send();
        if (xmlhttp.status==200) {
            result = xmlhttp.responseText;
        }
        return result;
    }
    
    function loadLabels(filePath) {
        return loadFile(filePath);
    }
    
    function loadEnv(filePath) {
        return JSON.parse(loadFile(filePath));
    }

    const constraints = {
        audio: false,
        video: {
            facingMode: "environment" // user or environment
        }
    };
    
    const getFrameFromVideo = (video, canvas) => {
        if (!live) {
            return;
        }
        const ctx = canvas.getContext("2d");
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        //ctx.save();
        ctx.drawImage(video, 0, 0, video.width, video.height);
        predict(video);
        ctx.font = "80px serif";
        ctx.fillStyle = infocolor;
        ctx.fillText(info, 50, 100);
        //ctx.restore();
        requestAnimationFrame(() => getFrameFromVideo(video, canvas));
    };
    
    const createVideo = (id, width, height) => {
        const video = document.createElement("video");
        video.id = id;
        video.width = width;
        video.height = height;
        video.autoplay = true;
        return video;
    };
    
    const createCanvas = (id, width, height) => {
        const canvas = document.createElement("canvas");
        canvas.id = id;
        canvas.width = width;
        canvas.height = height;
        return canvas;
    };
    
    const initLive = () => {
        console.log('initializing live ...')
        video = createVideo("vid", 800, 800);
        canvas = createCanvas("canvas", 800, 800);
        liveapp = document.getElementById("live");
        navigator.mediaDevices
            .getUserMedia(constraints)
            .then((stream) => {
                video.srcObject = stream;
                track = stream.getTracks()[0];  // keep for stop the stream when live be turned off
                video.onloadeddata = (event) => {
                    getFrameFromVideo(video, canvas);
                    liveview = liveapp.appendChild(canvas);
                    console.log("live initialized.");
                } 
            })
            .catch((error) => {  // open camera error
                console.log(error + ", please check your camera!");
                goLive();  // reset screen
            });
    };
    
    document.getElementById("select").onload = init();
</script>
